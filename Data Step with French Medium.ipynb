{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import math\n",
    "import quandl\n",
    "import collections, functools, operator\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from operator import itemgetter\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function cleans the data\n",
    "    '''\n",
    "    \n",
    "    data = data[data['date'] != 19251231]\n",
    "    #counts = data['date'].value_counts().to_dict()\n",
    "    \n",
    "    #adjust date format\n",
    "    data['date'] = data['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "    \n",
    "    \n",
    "    #remove PRC and SHROUT missing. According to the describtion, PRC missing meanings totally missing without a clue\n",
    "    data['PRC'] = pd.to_numeric(data.PRC, errors='coerce')\n",
    "    data = data.dropna(subset = ['PRC'])\n",
    "    data['PRC'] = data['PRC'].abs()\n",
    "    \n",
    "    data['SHROUT'] = pd.to_numeric(data.SHROUT, errors='coerce')\n",
    "    data = data.dropna(subset = ['SHROUT'])\n",
    "    \n",
    "    #get the medium\n",
    "    NYSE = pd.read_excel('NYSE medium.xlsx')\n",
    "    NYSE['date'] = pd.to_datetime(NYSE['date'])\n",
    "    data['YearMonth'] = data['date'].astype(str).apply(lambda x: x[:4] + x[5:7])\n",
    "    NYSE['YearMonth'] = NYSE['date'].astype(str).apply(lambda x: x[:4] + x[5:7])\n",
    "    NYSE = NYSE.drop(columns=['date'])    \n",
    "    data = pd.merge(data,NYSE,how = 'left',on = 'YearMonth')\n",
    "    data = data[data['YearMonth'] != '192512']\n",
    "    #counts = data['date'].value_counts().to_dict()\n",
    "    \n",
    "\n",
    "    data['mkt_cap'] = data['PRC']*data['SHROUT']\n",
    "    data = data[data['mkt_cap']*1000>data['market cap']] #SHROUT is approximate to 10**3\n",
    "\n",
    "    \n",
    "    #Remove ADR CLosed end fund and foreign fund\n",
    "    data['SHRCD'] = data.groupby(['CUSIP'])['SHRCD'].transform(lambda x: x.ffill())\n",
    "    data['SHRCD'] = data.groupby(['CUSIP'])['SHRCD'].transform(lambda x: x.bfill())\n",
    "    data = data[data['SHRCD'].isin([11.0,10.0])]\n",
    "    \n",
    "    \n",
    "    #check more than 5\n",
    "    mask = (data['PRC'] > 5)\n",
    "    data = data.loc[mask]\n",
    "\n",
    "    #clean the RET and RETX column. 'C' stands for the first trading month. Then we change it to 0\n",
    "    data['RET'] = data['RET'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    data['RETX'] =data['RETX'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    \n",
    "    data = data.drop(columns=['YearMonth'])\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_time_window(Start_Month, Start_Year, Time_Period_Training, Time_Period_Testing, Gap, data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function returns two cleaned datasets. One is the sampling period data and the other is testing period data\n",
    "    @variables: Start_Month: the starting month of our rolling time period\n",
    "                Start_Year: the starting year of our rolling time period\n",
    "                Time_Period_Training: Span of sampling Period\n",
    "                Time_Period_Testing: Span of testing Period\n",
    "                Gap: Gap between sampling and testing\n",
    "                Data: The input data dataset\n",
    "    @Also this function apply the filter no closed end fund and stock price more than 5 dollars\n",
    "    \n",
    "    @Updated: 10/7 fixed the end_date_test \"frequency = 0\" problem\n",
    "    @Updated: 10/16 change \"DATE\" to \"date\" to match the updated format\n",
    "    @Updated: 11/1 used the French's medium to substitute our formal medium which directly get from dataset\n",
    "    '''\n",
    "    \n",
    "    #get the start and end date of data\n",
    "    start_date_train = str(pd.date_range(start=str(Start_Month)+'/1/'+str(Start_Year), periods=1, freq='D')[0].date())\n",
    "    end_date_train = str(pd.date_range(start=str(Start_Month)+'/1/'+str(Start_Year), periods=2, freq=str(Time_Period_Training-1)+'M')[-1].date())\n",
    "    mask_train = (data['date'] >= start_date_train) & (data['date'] <= end_date_train)\n",
    "    \n",
    "    \n",
    "    start_month_testing = Start_Month+Time_Period_Training+Gap\n",
    "    if start_month_testing % 12 == 0:\n",
    "        start_year_testing = Start_Year + math.floor(start_month_testing/12)-1\n",
    "        start_month_testing = 12\n",
    "    else:\n",
    "        start_year_testing = Start_Year + math.floor(start_month_testing/12)\n",
    "        start_month_testing = start_month_testing % 12    \n",
    "    start_date_test = str(pd.date_range(start=str(start_month_testing)+'/1/'+str(start_year_testing), periods=1, freq='D')[0].date())\n",
    "    end_date_test = str(pd.date_range(start=str(start_month_testing)+'/1/'+str(start_year_testing), periods=1, freq=str(Time_Period_Testing)+'M')[-1].date())\n",
    "    mask_test = (data['date'] >= start_date_test) & (data['date'] <= end_date_test)\n",
    "    \n",
    "    #applying filter functions below on the master dataset\n",
    "    mask_master = (data['date'] >= start_date_train) & (data['date'] <= end_date_test)\n",
    "    data_master = data.loc[mask_master]\n",
    "    \n",
    "\n",
    "    full = []\n",
    "    for i in data_master['PERMNO'].values:\n",
    "        if (data_master[data_master['PERMNO'] == i]).shape[0] == (Time_Period_Training+ Time_Period_Testing+ Gap):\n",
    "            full.append(i)\n",
    "    data_master = data_master[data_master['PERMNO'].isin(full)]\n",
    "\n",
    "    \n",
    "    return data_master.loc[mask_train],data_master.loc[mask_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_FF():\n",
    "    '''\n",
    "    @author: Zhikang Wang\n",
    "    @The function read and clean up the fama_french dataset pulled from Dr. French's website\n",
    "    @Variable: input is fama_french dataset pulled from Dr. French's website\n",
    "    '''\n",
    "    \n",
    "    ff_data = pd.read_csv(\"fama_french.csv\")\n",
    "    # Getting and renaming the columns we need\n",
    "    ff_ret = ff_data[['YearMonth','Mkt-RF','SMB','HML','RF']]\n",
    "    ff_ret = ff_ret.rename(columns = {\"Mkt-RF\": \"mkt_ret\"})\n",
    "    # converting the factor exposures to percentage\n",
    "    ff_ret[\"mkt_ret\"] = ff_ret[\"mkt_ret\"]/100\n",
    "    ff_ret[\"SMB\"] = ff_ret[\"SMB\"]/100\n",
    "    ff_ret[\"HML\"] = ff_ret[\"HML\"]/100\n",
    "    ff_ret[\"RF\"] = ff_ret[\"RF\"]/100\n",
    "    ff_ret[\"YearMonth\"] = ff_ret[\"YearMonth\"].astype(str) #converting YearMonth to string\n",
    "    \n",
    "    return ff_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function add a column to the data set that assigned the weight to each stock for each month\n",
    "    @Variable: data: the input dataset (Monthly data)                    \n",
    "    '''\n",
    "    count = len(set(data['PERMNO'].values))\n",
    "    data['weight']=data.groupby(['date'])['RET'].apply(lambda x: (x-x.mean())*(-1/count))\n",
    "    data['weight'] = data.groupby(['PERMNO'])['weight'].shift(1)\n",
    "    data = data.dropna(subset = ['weight'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_Residual(data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function add a column to the data set that assigned the residual's weight to each stock for each month\n",
    "    @Variable: data: the input dataset (Monthly data)                    \n",
    "    '''\n",
    "    count = len(set(data['PERMNO'].values))\n",
    "    #data['residual_weight']=data.groupby(['YearMonth'])['residual'].apply(lambda x: (x-x.mean())*(-1/count)).shift(1)\n",
    "    data['residual_weight']=data.groupby(['YearMonth'])['residual'].apply(lambda x: (x-x.mean())*(-1/count))\n",
    "    data['residual_weight'] = data.groupby(['PERMNO'])['residual_weight'].shift(1)\n",
    "    data = data.dropna(subset = ['residual_weight'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equal_weight(data):\n",
    "    '''\n",
    "    @author: Zhikang Wang\n",
    "    @The function add a column to the data set that assigned equal weight to each stock for each month\n",
    "    @Variable: data: the input dataset (Monthly data)                    \n",
    "    '''\n",
    "    count = len(set(data['PERMNO'].values))\n",
    "    data['1'] = [1]*len(data)\n",
    "    data['equal_weight']=data.groupby(['date'])['1'].apply(lambda x: x*(1/count)).shift(1)\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_Grundy(df_conditional):\n",
    "    '''\n",
    "    @author: Robin Lam, Zhikang Wang\n",
    "    This function formats the dataframe which is used in the conditional factor model in the spirit of Grundy.\n",
    "        if excess returns on the RMRF, SMB, HML factors in month t are positive, use that factor;\n",
    "        otherwise, factor = 0.\n",
    "    Input:\n",
    "        df_conditional: dataframe acquired after running the regression model for each stock (TOTAL)\n",
    "            variables: the ones from output.csv\n",
    "    Output:\n",
    "        df_conditional: same dataframe as the input, but added the following: mkt_ret_UP, SMB_UP, HML_UP\n",
    "            variables: YearMonth, PERMNO, mkt_ret, SMB, HML, RF, ticker_ret, ticker_excess_ret, weight,\n",
    "                       mkt_ret_UP, SMB_UP, HML_UP\n",
    "    '''\n",
    "    df_conditional = df_conditional[['YearMonth','PERMNO','mkt_ret','SMB','HML','RF',\n",
    "                                    'ticker_ret','ticker_excess_ret','weight',\n",
    "                                    'mkt_factor','SMB_factor','HML_factor']]\n",
    "    \n",
    "    df_conditional['mkt_factor'] = df_conditional.groupby(['PERMNO'])['mkt_factor'].apply(lambda x: x.shift(1))\n",
    "    df_conditional['SMB_factor'] = df_conditional.groupby(['PERMNO'])['SMB_factor'].apply(lambda x: x.shift(1))\n",
    "    df_conditional['HML_factor'] = df_conditional.groupby(['PERMNO'])['HML_factor'].apply(lambda x: x.shift(1))\n",
    "    df_conditional = df_conditional.dropna()\n",
    "    df_conditional.loc[df_conditional['mkt_factor'] > 0, 'mkt_ret_UP'] = df_conditional['mkt_ret']    # this month, t\n",
    "    df_conditional.loc[df_conditional['mkt_factor'] <= 0, 'mkt_ret_UP'] = 0 \n",
    "    df_conditional.loc[df_conditional['SMB_factor'] > 0, 'SMB_UP'] = df_conditional['SMB']    # this month, t\n",
    "    df_conditional.loc[df_conditional['SMB_factor'] <= 0, 'SMB_UP'] = 0\n",
    "    df_conditional.loc[df_conditional['HML_factor'] > 0, 'HML_UP'] = df_conditional['HML']    # this month, t\n",
    "    df_conditional.loc[df_conditional['HML_factor'] <= 0, 'HML_UP'] = 0\n",
    "    df_conditional = df_conditional.drop(columns=['mkt_factor','SMB_factor','HML_factor'])\n",
    "    \n",
    "    return df_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(combined_temp):\n",
    "    '''\n",
    "    @author: Robin Lam, Yulin Chen, Wuding Li\n",
    "    Given each stock i, this function runs the regression model.\n",
    "    Input:\n",
    "        combined_temp: dataframe which contains returns and factor exposures\n",
    "            variables: YearMonth, mkt_ret, SMB, HML, RF, PERMNO, ticker_ret, ticker_excess_ret\n",
    "    Output:\n",
    "        combined_temp: same dataframe as the input, but with an extra column (residual)\n",
    "    \n",
    "    @Update: 10/16/2019: Wuding Li Change the output date to match the paper \n",
    "    '''\n",
    "    x = combined_temp[['mkt_ret','SMB','HML']]\n",
    "    y = combined_temp['ticker_excess_ret']\n",
    "    \n",
    "    # Linear regression model\n",
    "    x = sm.add_constant(x)\n",
    "    regressor = sm.OLS(y, x).fit()\n",
    "    # retrieving the slope\n",
    "    coef = regressor.params\n",
    "    # retrieving the t-statistics\n",
    "    t_test = regressor.pvalues\n",
    "    # retrieving the r-squared\n",
    "    r_squared = regressor.rsquared\n",
    "    \n",
    "    # calculating the residuals for each regression model\n",
    "    combined_temp['residual'] = y - x['mkt_ret']*coef[1] - x['SMB']*coef[2] - x['HML']*coef[3] - coef[0]\n",
    "    combined_temp['mkt_factor'] = x['mkt_ret']*coef[1]    #used in conditiona_factor_model\n",
    "    combined_temp['SMB_factor'] = x['SMB']*coef[2]    #used in conditiona_factor_model\n",
    "    combined_temp['HML_factor'] = x['HML']*coef[3]    #used in conditiona_factor_model\n",
    "    \n",
    "    # adding coefficients to columns\n",
    "    combined_temp['alpha'] = coef[0]\n",
    "    combined_temp['mkt_beta'] = coef[1]\n",
    "    combined_temp['SMB_beta'] = coef[2]\n",
    "    combined_temp['HML_beta'] = coef[3]\n",
    "    combined_temp['r_squared'] = r_squared\n",
    "    \n",
    "    # adding t-statistics to columns\n",
    "    combined_temp['t_alpha'] = t_test[0]\n",
    "    combined_temp['t_mkt_beta'] = t_test[1]\n",
    "    combined_temp['t_SMB_beta'] = t_test[2]\n",
    "    combined_temp['t_HML_beta'] = t_test[3]\n",
    "    \n",
    "    \n",
    "    combined_temp['port_mkt_beta'] = combined_temp['mkt_beta']*combined_temp['weight']\n",
    "    combined_temp['port_SMB_beta'] = combined_temp['SMB_beta']*combined_temp['weight']\n",
    "    combined_temp['port_HML_beta'] = combined_temp['HML_beta']*combined_temp['weight']\n",
    "    \n",
    "    standard_dev = combined_temp['residual'].std() #get the sd of the residual\n",
    "      \n",
    "#     keep = [sorted(list(set(combined_temp['YearMonth'].values)))[-1],sorted(list(set(combined_temp['YearMonth'].values)))[-2]]\n",
    "#     output = combined_temp[combined_temp['YearMonth'].isin(keep)]\n",
    "    return combined_temp, standard_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_factor_model(temp_conditional):\n",
    "    '''\n",
    "    @author: Robin Lam\n",
    "    This function is for running the regression in the spirit of Grundy and Martin.\n",
    "    Input:\n",
    "        temp_conditional: dataframe which contains returns and factor exposures\n",
    "            variables: YearMonth, PERMNO, mkt_ret, SMB, HML, RF, ticker_ret, ticker_excess_ret, weight,\n",
    "                       mkt_ret_UP, SMB_UP, HML_UP\n",
    "    Output:\n",
    "        temp_conditional: same dataframe as the input, but with an extra column (residual)\n",
    "            variables: YearMonth, PERMNO, mkt_ret, SMB, HML, RF, ticker_ret, ticker_excess_ret, weight,\n",
    "                       mkt_ret_UP, SMB_UP, HML_UP, residual, alpha, mkt_beta, SMB_beta, HML_beta,\n",
    "                       mkt_UP_beta, SMB_UP_beta, HML_UP_beta, t_mkt_beta, t_SMB_beta, t_HML_beta,\n",
    "                       t_mkt_UP_beta, t_SMB_UP_beta, t_HML_UP_beta\n",
    "    '''\n",
    "    x = temp_conditional[['mkt_ret','SMB','HML','mkt_ret_UP','SMB_UP','HML_UP']]\n",
    "    y = temp_conditional['ticker_excess_ret']\n",
    "\n",
    "    # Linear regression model\n",
    "    x = sm.add_constant(x)\n",
    "    regressor = sm.OLS(y, x).fit()\n",
    "    # retrieving the slope\n",
    "    coef = regressor.params\n",
    "    # retrieving the t-statistics\n",
    "    t_test = regressor.pvalues\n",
    "    # retrieving the r-squared\n",
    "    r_squared = regressor.rsquared\n",
    "    \n",
    "    # calculating the residuals for each regression model\n",
    "    # temp_conditional has 36 rows (36 months)\n",
    "    temp_conditional['residual'] = (y - x['mkt_ret']*coef[1] - x['SMB']*coef[2] - x['HML']*coef[3] -\n",
    "                                    x['mkt_ret_UP']*coef[4] - x['SMB_UP']*coef[5] - x['HML_UP']*coef[6] - coef[0])\n",
    "    \n",
    "    # adding coefficients to columns\n",
    "    temp_conditional['alpha'] = coef[0]\n",
    "    temp_conditional['mkt_beta'] = coef[1]\n",
    "    temp_conditional['SMB_beta'] = coef[2]\n",
    "    temp_conditional['HML_beta'] = coef[3]\n",
    "    temp_conditional['mkt_UP_beta'] = coef[4]\n",
    "    temp_conditional['SMB_UP_beta'] = coef[5]\n",
    "    temp_conditional['HML_UP_beta'] = coef[6]\n",
    "    temp_conditional['r_squared'] = r_squared\n",
    "    \n",
    "    # adding t-statistics to columns\n",
    "    temp_conditional['t_alpha'] = t_test[0]\n",
    "    temp_conditional['t_mkt_beta'] = t_test[1]\n",
    "    temp_conditional['t_SMB_beta'] = t_test[2]\n",
    "    temp_conditional['t_HML_beta'] = t_test[3]\n",
    "    temp_conditional['t_mkt_UP_beta'] = t_test[4]\n",
    "    temp_conditional['t_SMB_UP_beta'] = t_test[5]\n",
    "    temp_conditional['t_HML_UP_beta'] = t_test[6]\n",
    "  \n",
    "    # get t-2, t-1 from \"train\"\n",
    "    keep = [sorted(list(set(temp_conditional['YearMonth'].values)))[-1],sorted(list(set(temp_conditional['YearMonth'].values)))[-2]]\n",
    "    output = temp_conditional[temp_conditional['YearMonth'].isin(keep)]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regression(df):\n",
    "    '''\n",
    "    @author: Robin Lam, Wuding Li\n",
    "    Given each stock i, this function runs the regression model.\n",
    "    Input:\n",
    "        df: dataframe which contains ALL of the stocks' returns and factor exposures\n",
    "            variables: YearMonth, mkt_ret, SMB, HML, RF, PERMNO, ticker_ret, ticker_excess_ret\n",
    "    Output:\n",
    "        output: same dataframe as the input, but with an extra column (residual)\n",
    "        dict_coef: dictionary of coefficients from all the regression for ALL stocks. should have 3 betas.\n",
    "        \n",
    "    @Update: 10/16/2019: Wuding Li Change the output format of the function and the structure of the function\n",
    "    '''\n",
    "    output = pd.DataFrame()\n",
    "    output_temp = pd.DataFrame()\n",
    "    permno_list = list(set(df['PERMNO'].values.tolist()))\n",
    "    sd_dic = {}\n",
    "    for i in permno_list:\n",
    "        temp_train = df[df['PERMNO'] == i]\n",
    "        combined_temp, sd = regression_model(temp_train)    #there are 36 months in temp_train (individual ticker)\n",
    "        output_temp = output_temp.append(combined_temp)\n",
    "        keep = [sorted(list(set(combined_temp['YearMonth'].values)))[-1],sorted(list(set(combined_temp['YearMonth'].values)))[-2]]\n",
    "        output_keep = combined_temp[combined_temp['YearMonth'].isin(keep)]\n",
    "        sd_dic[i] = sd\n",
    "        output = output.append(output_keep)\n",
    "    output = get_weight_Residual(output)   #this is also returned to merge with the test dataset for later!\n",
    "        \n",
    "    '''\n",
    "    @author: Robin Lam\n",
    "    Evaluating the reversal returns using a conditional factor model (Grundy and Martin)\n",
    "    \n",
    "        if excess returns on the RMRF, SMB, HML factors in month t are positive, use that factor;\n",
    "        otherwise, factor = 0.\n",
    "    '''\n",
    "    df_conditional = format_Grundy(output_temp)\n",
    "    output_conditional = pd.DataFrame()\n",
    "    permno_list_conditional = list(set(df_conditional['PERMNO'].values.tolist()))\n",
    "    for i in permno_list_conditional:\n",
    "        temp_conditional = df_conditional[df_conditional['PERMNO'] == i]    #going through each ticker\n",
    "        combined_ret = conditional_factor_model(temp_conditional)    #running Grundy regression\n",
    "        output_conditional = output_conditional.append(combined_ret)\n",
    "    output_conditional = get_weight_Residual(output_conditional)    #adding residual weight\n",
    "    \n",
    "    #get the exposure of residual weighted portfolio\n",
    "    output['residual_port_mkt_beta'] = output['mkt_beta']*output['residual_weight']\n",
    "    output['residual_port_SMB_beta'] = output['SMB_beta']*output['residual_weight']\n",
    "    output['residual_port_HML_beta'] = output['HML_beta']*output['residual_weight']\n",
    "\n",
    "    return sd_dic, output, output_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grundy_Table(output_conditional, monthly_Grundy):\n",
    "    '''\n",
    "    ------------------------- NOT USED YET! -------------------------\n",
    "    @author: Robin Lam\n",
    "    This function gathers and outputs the things we need to replicate Table 1.\n",
    "    Input:\n",
    "        output_conditional: dataframe which was generated from the Grundy regression model.\n",
    "    Output:\n",
    "        monthly_Grundy: a dictionary which contains information for one month.\n",
    "    '''\n",
    "    #monthly_Grundy = {}\n",
    "    output_conditional['monthly_ret'] = output_conditional['ticker_ret']*output_conditional['weight']\n",
    "    sum_ret = output_conditional['monthly_ret'].sum()\n",
    "    output_conditional['monthly_residual_ret'] = output_conditional['residual']*output_conditional['residual_weight']\n",
    "    sum_residual_ret = output_conditional['monthly_residual_ret'].sum()\n",
    "    #monthly_Grundy['sum_ret'] = sum_ret\n",
    "    #monthly_Grundy['sum_residual_ret'] = sum_residual_ret\n",
    "    \n",
    "    output_conditional['residual_port_alpha'] = output_conditional['alpha']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_mkt_beta'] = output_conditional['mkt_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_SMB_beta'] = output_conditional['SMB_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_HML_beta'] = output_conditional['HML_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_mkt_UP_beta'] = output_conditional['mkt_UP_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_SMB_UP_beta'] = output_conditional['SMB_UP_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_HML_UP_beta'] = output_conditional['HML_UP_beta']*output_conditional['residual_weight']\n",
    "    \n",
    "    # Grundy table for conventional reversal strategy\n",
    "    sum_port_alpha = output_conditional['port_alpha'].sum()\n",
    "    sum_port_mkt_beta = output_conditional['port_mkt_beta'].sum()\n",
    "    sum_port_SMB_beta = output_conditional['port_SMB_beta'].sum()\n",
    "    sum_port_HML_beta = output_conditional['port_HML_beta'].sum()\n",
    "    sum_port_mkt_UP_beta = output_conditional['port_mkt_UP_beta'].sum()\n",
    "    sum_port_SMB_UP_beta = output_conditional['port_SMB_UP_beta'].sum()\n",
    "    sum_port_HML_UP_beta = output_conditional['port_HML_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_alpha'] = output_conditional['port_alpha'].sum()\n",
    "#     monthly_Grundy['sum_port_mkt_beta'] = output_conditional['port_mkt_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_SMB_beta'] = output_conditional['port_SMB_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_HML_beta'] = output_conditional['port_HML_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_mkt_UP_beta'] = output_conditional['port_mkt_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_SMB_UP_beta'] = output_conditional['port_SMB_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_HML_UP_beta'] = output_conditional['port_HML_UP_beta'].sum()\n",
    "    \n",
    "    # Grundy table for residual reversal strategy\n",
    "    sum_residual_port_alpha = output_conditional['residual_port_alpha'].sum()\n",
    "    sum_residual_port_mkt_beta = output_conditional['residual_port_mkt_beta'].sum()\n",
    "    sum_residual_port_SMB_beta = output_conditional['residual_port_SMB_beta'].sum()\n",
    "    sum_residual_port_HML_beta = output_conditional['residual_port_HML_beta'].sum()\n",
    "    sum_residual_port_mkt_UP_beta = output_conditional['residual_port_mkt_UP_beta'].sum()\n",
    "    sum_residual_port_SMB_UP_beta = output_conditional['residual_port_SMB_UP_beta'].sum()\n",
    "    sum_residual_port_HML_UP_beta = output_conditional['residual_port_HML_UP_beta'].sum()\n",
    "\n",
    "#     monthly_Grundy['sum_residual_port_alpha'] = output_conditional['residual_port_alpha'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_mkt_beta'] = output_conditional['residual_port_mkt_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_SMB_beta'] = output_conditional['residual_port_SMB_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_HML_beta'] = output_conditional['residual_port_HML_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_mkt_UP_beta'] = output_conditional['residual_port_mkt_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_SMB_UP_beta'] = output_conditional['residual_port_SMB_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_HML_UP_beta'] = output_conditional['residual_port_HML_UP_beta'].sum()\n",
    "    \n",
    "    monthly_Grundy = monthly_Grundy.append({'sum_ret': sum_ret, 'sum_residual_ret': sum_residual_ret,\n",
    "                                           'sum_port_alpha': sum_port_alpha, 'sum_port_mkt_beta': sum_port_mkt_beta,\n",
    "                                           'sum_port_SMB_beta': sum_port_SMB_beta, 'sum_port_HML_beta': sum_port_HML_beta,\n",
    "                                           'sum_port_mkt_UP_beta': sum_port_mkt_UP_beta,\n",
    "                                           'sum_port_SMB_UP_beta': sum_port_SMB_UP_beta,\n",
    "                                           'sum_port_HML_UP_beta': sum_port_HML_UP_beta,\n",
    "                                           'sum_residual_port_alpha': sum_residual_port_alpha,\n",
    "                                           'sum_residual_port_mkt_beta': sum_residual_port_mkt_beta,\n",
    "                                           'sum_residual_port_SMB_beta': sum_residual_port_SMB_beta,\n",
    "                                           'sum_residual_port_HML_beta': sum_residual_port_HML_beta,\n",
    "                                           'sum_residual_port_mkt_UP_beta': sum_residual_port_mkt_UP_beta,\n",
    "                                           'sum_residual_port_SMB_UP_beta': sum_residual_port_SMB_UP_beta,\n",
    "                                           'sum_residual_port_HML_UP_beta': sum_residual_port_HML_UP_beta},\n",
    "                                           ignore_index=True)\n",
    "                                            \n",
    "    return monthly_Grundy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf = pd.read_csv('msf.csv')\n",
    "msf = data_cleaning(msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Zhikang Wang / Yulin Chen\n",
    "MAIN FUNCTION.\n",
    "Loop over the period from 1986 to generate rolling regression\n",
    "'''\n",
    "\n",
    "test_port = pd.DataFrame() #container for test df\n",
    "'''\n",
    "mkt_beta_winner_output = []\n",
    "SMB_beta_winner_output = []\n",
    "HML_beta_winner_output = []\n",
    "mkt_beta_loser_output = []\n",
    "SMB_beta_loser_output = []\n",
    "HML_beta_loser_output = []\n",
    "residual_mkt_beta_winner_output = []\n",
    "residual_SMB_beta_winner_output = []\n",
    "residual_HML_beta_winner_output = []\n",
    "residual_mkt_beta_loser_output = []\n",
    "residual_SMB_beta_loser_output = []\n",
    "residual_HML_beta_loser_output = []\n",
    "'''\n",
    "output_conditional_output = pd.DataFrame()    #container for Grundy Table output\n",
    "\n",
    "total_train_output = pd.DataFrame()\n",
    "\n",
    "dates = []\n",
    "ff = []\n",
    "start = 1929\n",
    "\n",
    "for i in range(710,944): #（7，328） （329，650） （651，944）\n",
    "    if (i%12) != 0:\n",
    "        month = i%12\n",
    "        year = i // 12 + start\n",
    "    if (i%12) == 0: \n",
    "        month = 12\n",
    "        year = i // 12 + start -1\n",
    "\n",
    "    ff_ret = format_FF()\n",
    "    train,test = rolling_time_window(month, year, 37, 1, 0, msf)\n",
    "    #train = get_equal_weight(train)\n",
    "    train = get_weight(train)\n",
    "    \n",
    "    train = train.rename(columns = {\"RET\": \"ticker_ret\", \"date\": \"YearMonth\"})\n",
    "    train = train[['YearMonth','PERMNO','ticker_ret','weight']]\n",
    "    train[\"PERMNO\"] = train[\"PERMNO\"].astype(str)\n",
    "    test[\"PERMNO\"] = test[\"PERMNO\"].astype(str)\n",
    "    train[\"YearMonth\"] = train[\"YearMonth\"].astype(str)\n",
    "    train['YearMonth'] = train['YearMonth'].apply(lambda x: x[:4] + x[5:7])\n",
    "    # Merging the two dataset into one combined return dataset, which will be used as regression input\n",
    "    combined_ret = pd.merge(ff_ret, train, how='right', on=['YearMonth'])\n",
    "    # calculates the excess return of tickers by subtracting the returns by risk free rate\n",
    "    combined_ret['ticker_excess_ret'] = combined_ret['ticker_ret'] - combined_ret['RF']\n",
    "    #append dates\n",
    "    month_list=[\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "    month=month_list[month-1]\n",
    "#     year = year + 3\n",
    "    str_date = str(year)+str(month)\n",
    "    dates.append(str_date)\n",
    "        \n",
    "    sd_dic, output, output_conditional = all_regression(combined_ret)\n",
    "    output_conditional_output = output_conditional_output.append(output_conditional)\n",
    "    total_train_output = total_train_output.append(output)\n",
    "#     monthly_Grundy = pd.DataFrame()\n",
    "    monthly_Grundy = pd.DataFrame(columns=['sum_ret','sum_residual_ret','sum_port_alpha','sum_port_mkt_beta',\n",
    "                                          'sum_port_SMB_beta','sum_port_HML_beta','sum_port_mkt_UP_beta',\n",
    "                                          'sum_port_SMB_UP_beta','sum_port_HML_UP_beta','sum_residual_port_alpha',\n",
    "                                          'sum_residual_port_mkt_beta','sum_residual_port_SMB_beta',\n",
    "                                          'sum_residual_port_HML_beta','sum_residual_port_mkt_UP_beta',\n",
    "                                          'sum_residual_port_SMB_UP_beta','sum_residual_port_HML_UP_beta'])\n",
    "    #monthly_Grundy = Grundy_Table(output_conditional, monthly_Grundy)\n",
    "    #output_conditional_output = pd.concat([output_conditional_output, monthly_Grundy])\n",
    "    \n",
    "    sd_df = pd.DataFrame.from_dict(sd_dic, orient='index')\n",
    "    sd_df = sd_df.reset_index()\n",
    "    sd_df =  sd_df.rename(columns = {\"index\": \"PERMNO\", 0: 'std'})\n",
    "    test = pd.merge(test,sd_df, how = 'left', on  =['PERMNO'])\n",
    "    \n",
    "    # Testing portfolio\n",
    "    count = len(set(output['PERMNO'].values))\n",
    "    output['test_conv_weight']=output['ticker_ret'].apply(lambda x: (x-output['ticker_ret'].mean())*(-1/count))\n",
    "    output['test_red_weight'] = output['residual'].apply(lambda x: (x-output['residual'].mean())*(-1/count))\n",
    "    output = output[['PERMNO','test_conv_weight','test_red_weight']]\n",
    "    test = pd.merge(test,output,how = 'left',on=['PERMNO'])\n",
    "    test_port = test_port.append(test)\n",
    "    print(i)\n",
    "    '''    \n",
    "    mkt_beta_winner_output.append(mkt_beta_winner)\n",
    "    SMB_beta_winner_output.append(SMB_beta_winner)\n",
    "    HML_beta_winner_output.append(HML_beta_winner)\n",
    "    mkt_beta_loser_output.append(mkt_beta_loser)\n",
    "    SMB_beta_loser_output.append(SMB_beta_loser)\n",
    "    HML_beta_loser_output.append(HML_beta_loser)\n",
    "    \n",
    "    residual_mkt_beta_winner_output.append(mkt_beta_winner_res)\n",
    "    residual_SMB_beta_winner_output.append(SMB_beta_winner_res)\n",
    "    residual_HML_beta_winner_output.append(HML_beta_winner_res)\n",
    "    residual_mkt_beta_loser_output.append(mkt_beta_loser_res)\n",
    "    residual_SMB_beta_loser_output.append(SMB_beta_loser_res)\n",
    "    residual_HML_beta_loser_output.append(HML_beta_loser_res)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154778"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv1 = total_train_output.to_csv ('train_output4.csv', index = None, header=True)\n",
    "export_csv2 = test_port.to_csv ('test_output4.csv', index = None, header=True)\n",
    "export_csv3 = output_conditional_output.to_csv ('conditional_output4.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
