{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import math\n",
    "import quandl\n",
    "import collections, functools, operator\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from operator import itemgetter\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function cleans the data\n",
    "    '''\n",
    "    \n",
    "    data = data[data['date'] != 19251231]\n",
    "    #counts = data['date'].value_counts().to_dict()\n",
    "    \n",
    "    #adjust date format\n",
    "    data['date'] = data['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "    \n",
    "    \n",
    "    #remove PRC and SHROUT missing. According to the describtion, PRC missing meanings totally missing without a clue\n",
    "    data['PRC'] = pd.to_numeric(data.PRC, errors='coerce')\n",
    "    data = data.dropna(subset = ['PRC'])\n",
    "    data['PRC'] = data['PRC'].abs()\n",
    "    \n",
    "    data['SHROUT'] = pd.to_numeric(data.SHROUT, errors='coerce')\n",
    "    data = data.dropna(subset = ['SHROUT'])\n",
    "    \n",
    "    #get the medium\n",
    "    NYSE = pd.read_excel('NYSE medium.xlsx')\n",
    "    NYSE['date'] = pd.to_datetime(NYSE['date'])\n",
    "    data['YearMonth'] = data['date'].astype(str).apply(lambda x: x[:4] + x[5:7])\n",
    "    NYSE['YearMonth'] = NYSE['date'].astype(str).apply(lambda x: x[:4] + x[5:7])\n",
    "    NYSE = NYSE.drop(columns=['date'])    \n",
    "    data = pd.merge(data,NYSE,how = 'left',on = 'YearMonth')\n",
    "    data = data[data['YearMonth'] != '192512']\n",
    "    #counts = data['date'].value_counts().to_dict()\n",
    "    \n",
    "\n",
    "    data['mkt_cap'] = data['PRC']*data['SHROUT']\n",
    "    data = data[data['mkt_cap']*1000>data['market cap']] #SHROUT is approximate to 10**3\n",
    "\n",
    "    \n",
    "    #Remove ADR CLosed end fund and foreign fund\n",
    "    data['SHRCD'] = data.groupby(['CUSIP'])['SHRCD'].transform(lambda x: x.ffill())\n",
    "    data['SHRCD'] = data.groupby(['CUSIP'])['SHRCD'].transform(lambda x: x.bfill())\n",
    "    data = data[data['SHRCD'].isin([11.0,10.0])]\n",
    "    \n",
    "    \n",
    "    #check more than 5\n",
    "    mask = (data['PRC'] > 5)\n",
    "    data = data.loc[mask]\n",
    "\n",
    "    #clean the RET and RETX column. 'C' stands for the first trading month. Then we change it to 0\n",
    "    data['RET'] = data['RET'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    data['RETX'] =data['RETX'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    \n",
    "    data = data.drop(columns=['YearMonth'])\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_time_window(Start_Month, Start_Year, Time_Period_Training, Time_Period_Testing, Gap, data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function returns two cleaned datasets. One is the sampling period data and the other is testing period data\n",
    "    @variables: Start_Month: the starting month of our rolling time period\n",
    "                Start_Year: the starting year of our rolling time period\n",
    "                Time_Period_Training: Span of sampling Period\n",
    "                Time_Period_Testing: Span of testing Period\n",
    "                Gap: Gap between sampling and testing\n",
    "                Data: The input data dataset\n",
    "    @Also this function apply the filter no closed end fund and stock price more than 5 dollars\n",
    "    \n",
    "    @Updated: 10/7 fixed the end_date_test \"frequency = 0\" problem\n",
    "    @Updated: 10/16 change \"DATE\" to \"date\" to match the updated format\n",
    "    @Updated: 11/1 used the French's medium to substitute our formal medium which directly get from dataset\n",
    "    '''\n",
    "    \n",
    "    #get the start and end date of data\n",
    "    start_date_train = str(pd.date_range(start=str(Start_Month)+'/1/'+str(Start_Year), periods=1, freq='D')[0].date())\n",
    "    end_date_train = str(pd.date_range(start=str(Start_Month)+'/1/'+str(Start_Year), periods=2, freq=str(Time_Period_Training-1)+'M')[-1].date())\n",
    "    mask_train = (data['date'] >= start_date_train) & (data['date'] <= end_date_train)\n",
    "    \n",
    "    \n",
    "    start_month_testing = Start_Month+Time_Period_Training+Gap\n",
    "    if start_month_testing % 12 == 0:\n",
    "        start_year_testing = Start_Year + math.floor(start_month_testing/12)-1\n",
    "        start_month_testing = 12\n",
    "    else:\n",
    "        start_year_testing = Start_Year + math.floor(start_month_testing/12)\n",
    "        start_month_testing = start_month_testing % 12    \n",
    "    start_date_test = str(pd.date_range(start=str(start_month_testing)+'/1/'+str(start_year_testing), periods=1, freq='D')[0].date())\n",
    "    end_date_test = str(pd.date_range(start=str(start_month_testing)+'/1/'+str(start_year_testing), periods=1, freq=str(Time_Period_Testing)+'M')[-1].date())\n",
    "    mask_test = (data['date'] >= start_date_test) & (data['date'] <= end_date_test)\n",
    "    \n",
    "    #applying filter functions below on the master dataset\n",
    "    mask_master = (data['date'] >= start_date_train) & (data['date'] <= end_date_test)\n",
    "    data_master = data.loc[mask_master]\n",
    "    \n",
    "\n",
    "    full = []\n",
    "    for i in data_master['PERMNO'].values:\n",
    "        if (data_master[data_master['PERMNO'] == i]).shape[0] == (Time_Period_Training+ Time_Period_Testing+ Gap):\n",
    "            full.append(i)\n",
    "    data_master = data_master[data_master['PERMNO'].isin(full)]\n",
    "\n",
    "    \n",
    "    return data_master.loc[mask_train],data_master.loc[mask_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_FF():\n",
    "    '''\n",
    "    @author: Zhikang Wang\n",
    "    @The function read and clean up the fama_french dataset pulled from Dr. French's website\n",
    "    @Variable: input is fama_french dataset pulled from Dr. French's website\n",
    "    '''\n",
    "    \n",
    "    ff_data = pd.read_csv(\"fama_french.csv\")\n",
    "    # Getting and renaming the columns we need\n",
    "    ff_ret = ff_data[['YearMonth','Mkt-RF','SMB','HML','RF']]\n",
    "    ff_ret = ff_ret.rename(columns = {\"Mkt-RF\": \"mkt_ret\"})\n",
    "    # converting the factor exposures to percentage\n",
    "    ff_ret[\"mkt_ret\"] = ff_ret[\"mkt_ret\"]/100\n",
    "    ff_ret[\"SMB\"] = ff_ret[\"SMB\"]/100\n",
    "    ff_ret[\"HML\"] = ff_ret[\"HML\"]/100\n",
    "    ff_ret[\"RF\"] = ff_ret[\"RF\"]/100\n",
    "    ff_ret[\"YearMonth\"] = ff_ret[\"YearMonth\"].astype(str) #converting YearMonth to string\n",
    "    \n",
    "    return ff_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function add a column to the data set that assigned the weight to each stock for each month\n",
    "    @Variable: data: the input dataset (Monthly data)  \n",
    "    @update: 11/17/2019 Wuding Li updated the weight function by Lehmann(1990)\n",
    "    '''\n",
    "    #count = len(set(data['PERMNO'].values))  \n",
    "    data['weight_temp'] = data.groupby(['date'])['RET'].apply(lambda x: (x-x.mean()))\n",
    "    data['weight_temp1']= data['weight_temp'].apply(lambda x: 0 if x<0 else x)\n",
    "    data['weight_temp1'] = data['weight_temp1'].groupby(data['date']).transform('sum')\n",
    "    data['weight'] = data['weight_temp']/data['weight_temp1']\n",
    "    data = data.drop(columns=['weight_temp','weight_temp1'])\n",
    "    data['weight'] = data.groupby(['PERMNO'])['weight'].shift(1)\n",
    "    data = data.dropna(subset = ['weight'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_Residual(data):\n",
    "    '''\n",
    "    @author: Wuding Li\n",
    "    @The function add a column to the data set that assigned the residual's weight to each stock for each month\n",
    "    @Variable: data: the input dataset (Monthly data)                    \n",
    "    '''\n",
    "    \n",
    "    count = len(set(data['PERMNO'].values))\n",
    "    #data['residual_weight']=data.groupby(['YearMonth'])['residual'].apply(lambda x: (x-x.mean())*(-1/count)).shift(1)\n",
    "    #data['residual_weight']=data.groupby(['YearMonth'])['residual'].apply(lambda x: (x-x.mean())*(-1/count))\n",
    "    def resd_avg(df):\n",
    "        result = (df['residual'] - df['residual_mean'])\n",
    "        #print(result)\n",
    "        return result\n",
    "    #data['residual_weight'] = data.groupby(['YearMonth']).apply(resd_avg)\n",
    "    \n",
    "    temp_output = pd.DataFrame()\n",
    "    YearMonth_list = list(set(data['YearMonth'].values.tolist()))\n",
    "    for i in YearMonth_list:\n",
    "        temp = data[data['YearMonth'] == i]\n",
    "        temp['residual_weight'] = (temp['residual'] - temp['residual_mean'])\n",
    "        temp['residual_weight_winner'] = temp['residual_weight'].apply(lambda x: 0 if x<0 else x)\n",
    "        temp['residual_real_weight'] = temp['residual_weight']/(temp['residual_weight_winner'].sum())\n",
    "        temp_output = temp_output.append(temp)\n",
    "        \n",
    "    \n",
    "    #data['residual_weight']=data.groupby(['YearMonth'])['residual_weight'].apply(lambda x: (x*-1/count))\n",
    "    #data['residual_weight']=data.groupby(['YearMonth'])[['residual','residual_mean']].apply(lambda x,y: (x-y))\n",
    "    temp_output = temp_output.sort_values(by=['YearMonth'])\n",
    "    temp_output['residual_weight'] = temp_output.groupby(['PERMNO'])['residual_weight'].shift(1)\n",
    "    temp_output = temp_output.dropna(subset = ['residual_weight'])\n",
    "    #temp_output['residual_weight'] = temp_output['residual_weight']*(-1/count)\n",
    "    return temp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equal_weight(data):\n",
    "    '''\n",
    "    @author: Zhikang Wang\n",
    "    @The function add a column to the data set that assigned equal weight to each stock for each month\n",
    "    @Variable: data: the input dataset (Monthly data)                    \n",
    "    '''\n",
    "    count = len(set(data['PERMNO'].values))\n",
    "    data['1'] = [1]*len(data)\n",
    "    data['equal_weight']=data.groupby(['date'])['1'].apply(lambda x: x*(1/count)).shift(1)\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_Grundy(df_conditional):\n",
    "    '''\n",
    "    @author: Robin Lam, Zhikang Wang\n",
    "    This function formats the dataframe which is used in the conditional factor model in the spirit of Grundy.\n",
    "        if excess returns on the RMRF, SMB, HML factors in month t are positive, use that factor;\n",
    "        otherwise, factor = 0.\n",
    "    Input:\n",
    "        df_conditional: dataframe acquired after running the regression model for each stock (TOTAL)\n",
    "            variables: the ones from output.csv\n",
    "    Output:\n",
    "        df_conditional: same dataframe as the input, but added the following: mkt_ret_UP, SMB_UP, HML_UP\n",
    "            variables: YearMonth, PERMNO, mkt_ret, SMB, HML, RF, ticker_ret, ticker_excess_ret, weight,\n",
    "                       mkt_ret_UP, SMB_UP, HML_UP\n",
    "    '''\n",
    "    df_conditional = df_conditional[['YearMonth','PERMNO','mkt_ret','SMB','HML','RF','ticker_ret','ticker_excess_ret','weight',\n",
    "                                 'mkt_beta','SMB_beta','HML_beta','mkt_factor','SMB_factor','HML_factor']]\n",
    "\n",
    "    # calculating the sum of all returns on factors and shifting all returns on factors down 1 (t-1)\n",
    "    df_sum_factors = df_conditional.groupby(['YearMonth'])[['mkt_factor','SMB_factor','HML_factor']].apply(lambda x: x.sum())\n",
    "    df_sum_factors = df_sum_factors.rename(columns={'mkt_factor':'mkt_factor_prev', 'SMB_factor':'SMB_factor_prev', 'HML_factor':'HML_factor_prev'})\n",
    "    df_sum_factors = df_sum_factors.shift(1)\n",
    "    df_combined = pd.merge(df_conditional, df_sum_factors, how='left', on=['YearMonth'])\n",
    "    df_combined = df_combined.dropna()\n",
    "    df_combined = df_combined.sort_values(by=['YearMonth'])\n",
    "\n",
    "    # determining the interactive variables: RMRF_UP, SMB_UP, HML_UP\n",
    "    df_combined.loc[df_combined['mkt_factor_prev'] > 0, 'mkt_ret_UP'] = df_combined['mkt_factor']    # this month, t\n",
    "    df_combined.loc[df_combined['mkt_factor_prev'] <= 0, 'mkt_ret_UP'] = 0 \n",
    "    df_combined.loc[df_combined['SMB_factor_prev'] > 0, 'SMB_UP'] = df_combined['SMB_factor']    # this month, t\n",
    "    df_combined.loc[df_combined['SMB_factor_prev'] <= 0, 'SMB_UP'] = 0\n",
    "    df_combined.loc[df_combined['HML_factor_prev'] > 0, 'HML_UP'] = df_combined['HML_factor']    # this month, t\n",
    "    df_combined.loc[df_combined['HML_factor_prev'] <= 0, 'HML_UP'] = 0\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(combined_temp):\n",
    "    '''\n",
    "    @author: Robin Lam, Yulin Chen, Wuding Li\n",
    "    Given each stock i, this function runs the regression model.\n",
    "    Input:\n",
    "        combined_temp: dataframe which contains returns and factor exposures\n",
    "            variables: YearMonth, mkt_ret, SMB, HML, RF, PERMNO, ticker_ret, ticker_excess_ret\n",
    "    Output:\n",
    "        combined_temp: same dataframe as the input, but with an extra column (residual)\n",
    "    \n",
    "    @Update: 10/16/2019: Wuding Li Change the output date to match the paper \n",
    "    '''\n",
    "    x = combined_temp[['mkt_ret','SMB','HML']]\n",
    "    y = combined_temp['ticker_excess_ret']\n",
    "    \n",
    "    # Linear regression model\n",
    "    x = sm.add_constant(x)\n",
    "    regressor = sm.OLS(y, x).fit()\n",
    "    # retrieving the slope\n",
    "    coef = regressor.params\n",
    "    # retrieving the t-statistics\n",
    "    t_test = regressor.pvalues\n",
    "    # retrieving the r-squared\n",
    "    r_squared = regressor.rsquared_adj\n",
    "    \n",
    "    \n",
    "    # calculating the residuals for each regression model\n",
    "    combined_temp['residual'] = y - x['mkt_ret']*coef[1] - x['SMB']*coef[2] - x['HML']*coef[3] - coef[0]\n",
    "    standard_dev = combined_temp['residual'].std() #get the sd of the residual\n",
    "    avg_ret = combined_temp['residual'].mean()\n",
    "    combined_temp['residual_sd'] = (combined_temp['residual']-avg_ret)/standard_dev\n",
    "    combined_temp['residual_mean'] = combined_temp['residual_sd'].mean()\n",
    "    \n",
    "    combined_temp['mkt_factor'] = x['mkt_ret']*coef[1]    #used in conditiona_factor_model\n",
    "    combined_temp['SMB_factor'] = x['SMB']*coef[2]    #used in conditiona_factor_model\n",
    "    combined_temp['HML_factor'] = x['HML']*coef[3]    #used in conditiona_factor_model\n",
    "    \n",
    "    # adding coefficients to columns\n",
    "    combined_temp['alpha'] = coef[0]\n",
    "    combined_temp['mkt_beta'] = coef[1]\n",
    "    combined_temp['SMB_beta'] = coef[2]\n",
    "    combined_temp['HML_beta'] = coef[3]\n",
    "    combined_temp['r_squared'] = r_squared\n",
    "    \n",
    "    # adding t-statistics to columns\n",
    "    combined_temp['t_alpha'] = t_test[0]\n",
    "    combined_temp['t_mkt_beta'] = t_test[1]\n",
    "    combined_temp['t_SMB_beta'] = t_test[2]\n",
    "    combined_temp['t_HML_beta'] = t_test[3]\n",
    "    \n",
    "    \n",
    "    combined_temp['port_mkt_beta'] = combined_temp['mkt_beta']*combined_temp['weight']\n",
    "    combined_temp['port_SMB_beta'] = combined_temp['SMB_beta']*combined_temp['weight']\n",
    "    combined_temp['port_HML_beta'] = combined_temp['HML_beta']*combined_temp['weight']\n",
    "    \n",
    "      \n",
    "#     keep = [sorted(list(set(combined_temp['YearMonth'].values)))[-1],sorted(list(set(combined_temp['YearMonth'].values)))[-2]]\n",
    "#     output = combined_temp[combined_temp['YearMonth'].isin(keep)]\n",
    "    return combined_temp, standard_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_factor_model(temp_conditional):\n",
    "    '''\n",
    "    @author: Robin Lam\n",
    "    This function is for running the regression in the spirit of Grundy and Martin.\n",
    "    Input:\n",
    "        temp_conditional: dataframe which contains returns and factor exposures\n",
    "            variables: YearMonth, PERMNO, mkt_ret, SMB, HML, RF, ticker_ret, ticker_excess_ret, weight,\n",
    "                       mkt_ret_UP, SMB_UP, HML_UP\n",
    "    Output:\n",
    "        temp_conditional: same dataframe as the input, but with an extra column (residual)\n",
    "            variables: YearMonth, PERMNO, mkt_ret, SMB, HML, RF, ticker_ret, ticker_excess_ret, weight,\n",
    "                       mkt_ret_UP, SMB_UP, HML_UP, residual, alpha, mkt_beta, SMB_beta, HML_beta,\n",
    "                       mkt_UP_beta, SMB_UP_beta, HML_UP_beta, t_mkt_beta, t_SMB_beta, t_HML_beta,\n",
    "                       t_mkt_UP_beta, t_SMB_UP_beta, t_HML_UP_beta\n",
    "    '''\n",
    "    x = temp_conditional[['mkt_ret','SMB','HML','mkt_ret_UP','SMB_UP','HML_UP']]\n",
    "    y = temp_conditional['ticker_excess_ret']\n",
    "    print(x)\n",
    "    # Linear regression model\n",
    "    x = sm.add_constant(x)\n",
    "    regressor = sm.OLS(y, x).fit()\n",
    "    # retrieving the slope\n",
    "    coef = regressor.params\n",
    "    # retrieving the t-statistics\n",
    "    t_test = regressor.pvalues\n",
    "    # retrieving the r-squared\n",
    "    r_squared = regressor.rsquared_adj\n",
    "    print(coef)\n",
    "    \n",
    "    \n",
    "    # calculating the residuals for each regression model\n",
    "    # temp_conditional has many rows of single PERMNO\n",
    "    temp_conditional['residual'] = (y - x['mkt_ret']*coef[1] - x['SMB']*coef[2] - x['HML']*coef[3] -\n",
    "                                    x['mkt_ret_UP']*coef[4] - x['SMB_UP']*coef[5] - x['HML_UP']*coef[6] - coef[0])\n",
    "    standard_dev = temp_conditional['residual'].std() #get the sd of the residual\n",
    "    avg_ret = temp_conditional['residual'].mean()\n",
    "    temp_conditional['residual_sd'] = (temp_conditional['residual']-avg_ret)/standard_dev\n",
    "    temp_conditional['residual_mean'] = temp_conditional['residual_sd'].mean()\n",
    "    \n",
    "    # adding coefficients to columns\n",
    "    temp_conditional['alpha'] = coef[0]\n",
    "    temp_conditional['mkt_beta'] = coef[1]\n",
    "    temp_conditional['SMB_beta'] = coef[2]\n",
    "    temp_conditional['HML_beta'] = coef[3]\n",
    "    temp_conditional['mkt_UP_beta'] = coef[4]\n",
    "    temp_conditional['SMB_UP_beta'] = coef[5]\n",
    "    temp_conditional['HML_UP_beta'] = coef[6]\n",
    "    temp_conditional['r_squared'] = r_squared\n",
    "    \n",
    "    # adding t-statistics to columns\n",
    "    temp_conditional['t_alpha'] = t_test[0]\n",
    "    temp_conditional['t_mkt_beta'] = t_test[1]\n",
    "    temp_conditional['t_SMB_beta'] = t_test[2]\n",
    "    temp_conditional['t_HML_beta'] = t_test[3]\n",
    "    temp_conditional['t_mkt_UP_beta'] = t_test[4]\n",
    "    temp_conditional['t_SMB_UP_beta'] = t_test[5]\n",
    "    temp_conditional['t_HML_UP_beta'] = t_test[6]\n",
    "  \n",
    "    \n",
    "#     # get t-2, t-1\n",
    "#     keep = [sorted(list(set(temp_conditional['YearMonth'].values)))[-1],sorted(list(set(temp_conditional['YearMonth'].values)))[-2]]\n",
    "#     output = temp_conditional[temp_conditional['YearMonth'].isin(keep)]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_regression(df):\n",
    "    '''\n",
    "    @author: Robin Lam, Wuding Li\n",
    "    Given each stock i, this function runs the regression model.\n",
    "    Input:\n",
    "        df: dataframe which contains ALL of the stocks' returns and factor exposures\n",
    "            variables: YearMonth, mkt_ret, SMB, HML, RF, PERMNO, ticker_ret, ticker_excess_ret\n",
    "    Output:\n",
    "        output: same dataframe as the input, but with an extra column (residual)\n",
    "        dict_coef: dictionary of coefficients from all the regression for ALL stocks. should have 3 betas.\n",
    "        \n",
    "    @Update: 10/16/2019: Wuding Li Change the output format of the function and the structure of the function\n",
    "    '''\n",
    "    output = pd.DataFrame()\n",
    "    #output_temp = pd.DataFrame()\n",
    "    permno_list = list(set(df['PERMNO'].values.tolist()))\n",
    "    sd_dic = {}\n",
    "    for i in permno_list:\n",
    "        temp_train = df[df['PERMNO'] == i]\n",
    "        combined_temp, sd = regression_model(temp_train)    #there are 36 months in temp_train (individual ticker)\n",
    "        #output_temp = output_temp.append(combined_temp)\n",
    "        keep = [sorted(list(set(combined_temp['YearMonth'].values)))[-1],sorted(list(set(combined_temp['YearMonth'].values)))[-2]]\n",
    "        output_keep = combined_temp[combined_temp['YearMonth'].isin(keep)]\n",
    "        sd_dic[i] = sd\n",
    "        output = output.append(output_keep)\n",
    "    output = get_weight_Residual(output)   #this is also returned to merge with the test dataset for later!\n",
    "    \n",
    "#     '''\n",
    "#     @author: Robin Lam\n",
    "#     Evaluating the reversal returns using a conditional factor model (Grundy and Martin)\n",
    "    \n",
    "#         if excess returns on the RMRF, SMB, HML factors in month t are positive, use that factor;\n",
    "#         otherwise, factor = 0.\n",
    "#     '''\n",
    "#     df_conditional = format_Grundy(output_temp)\n",
    "#     output_conditional = pd.DataFrame()\n",
    "#     permno_list_conditional = list(set(df_conditional['PERMNO'].values.tolist()))\n",
    "#     #sd_dic_grundy = {}\n",
    "#     for i in permno_list_conditional:\n",
    "#         temp_conditional = df_conditional[df_conditional['PERMNO'] == i]    #going through each ticker\n",
    "#         combined_ret = conditional_factor_model(temp_conditional)    #running Grundy regression\n",
    "#         #sd_dic_grundy[i] = sd\n",
    "#         output_conditional = output_conditional.append(combined_ret)\n",
    "#     output_conditional = get_weight_Residual(output_conditional)    #adding residual weight\n",
    "\n",
    "    return sd_dic, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grundy_Table(output_conditional, monthly_Grundy):\n",
    "    '''\n",
    "    ------------------------- NOT USED YET! -------------------------\n",
    "    @author: Robin Lam\n",
    "    This function gathers and outputs the things we need to replicate Table 1.\n",
    "    Input:\n",
    "        output_conditional: dataframe which was generated from the Grundy regression model.\n",
    "    Output:\n",
    "        monthly_Grundy: a dictionary which contains information for one month.\n",
    "    '''\n",
    "    #monthly_Grundy = {}\n",
    "    output_conditional['monthly_ret'] = output_conditional['ticker_ret']*output_conditional['weight']\n",
    "    sum_ret = output_conditional['monthly_ret'].sum()\n",
    "    output_conditional['monthly_residual_ret'] = output_conditional['residual']*output_conditional['residual_weight']\n",
    "    sum_residual_ret = output_conditional['monthly_residual_ret'].sum()\n",
    "    #monthly_Grundy['sum_ret'] = sum_ret\n",
    "    #monthly_Grundy['sum_residual_ret'] = sum_residual_ret\n",
    "    \n",
    "    output_conditional['residual_port_alpha'] = output_conditional['alpha']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_mkt_beta'] = output_conditional['mkt_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_SMB_beta'] = output_conditional['SMB_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_HML_beta'] = output_conditional['HML_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_mkt_UP_beta'] = output_conditional['mkt_UP_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_SMB_UP_beta'] = output_conditional['SMB_UP_beta']*output_conditional['residual_weight']\n",
    "    output_conditional['residual_port_HML_UP_beta'] = output_conditional['HML_UP_beta']*output_conditional['residual_weight']\n",
    "    \n",
    "    # Grundy table for conventional reversal strategy\n",
    "    sum_port_alpha = output_conditional['port_alpha'].sum()\n",
    "    sum_port_mkt_beta = output_conditional['port_mkt_beta'].sum()\n",
    "    sum_port_SMB_beta = output_conditional['port_SMB_beta'].sum()\n",
    "    sum_port_HML_beta = output_conditional['port_HML_beta'].sum()\n",
    "    sum_port_mkt_UP_beta = output_conditional['port_mkt_UP_beta'].sum()\n",
    "    sum_port_SMB_UP_beta = output_conditional['port_SMB_UP_beta'].sum()\n",
    "    sum_port_HML_UP_beta = output_conditional['port_HML_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_alpha'] = output_conditional['port_alpha'].sum()\n",
    "#     monthly_Grundy['sum_port_mkt_beta'] = output_conditional['port_mkt_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_SMB_beta'] = output_conditional['port_SMB_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_HML_beta'] = output_conditional['port_HML_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_mkt_UP_beta'] = output_conditional['port_mkt_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_SMB_UP_beta'] = output_conditional['port_SMB_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_port_HML_UP_beta'] = output_conditional['port_HML_UP_beta'].sum()\n",
    "    \n",
    "    # Grundy table for residual reversal strategy\n",
    "    sum_residual_port_alpha = output_conditional['residual_port_alpha'].sum()\n",
    "    sum_residual_port_mkt_beta = output_conditional['residual_port_mkt_beta'].sum()\n",
    "    sum_residual_port_SMB_beta = output_conditional['residual_port_SMB_beta'].sum()\n",
    "    sum_residual_port_HML_beta = output_conditional['residual_port_HML_beta'].sum()\n",
    "    sum_residual_port_mkt_UP_beta = output_conditional['residual_port_mkt_UP_beta'].sum()\n",
    "    sum_residual_port_SMB_UP_beta = output_conditional['residual_port_SMB_UP_beta'].sum()\n",
    "    sum_residual_port_HML_UP_beta = output_conditional['residual_port_HML_UP_beta'].sum()\n",
    "\n",
    "#     monthly_Grundy['sum_residual_port_alpha'] = output_conditional['residual_port_alpha'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_mkt_beta'] = output_conditional['residual_port_mkt_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_SMB_beta'] = output_conditional['residual_port_SMB_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_HML_beta'] = output_conditional['residual_port_HML_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_mkt_UP_beta'] = output_conditional['residual_port_mkt_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_SMB_UP_beta'] = output_conditional['residual_port_SMB_UP_beta'].sum()\n",
    "#     monthly_Grundy['sum_residual_port_HML_UP_beta'] = output_conditional['residual_port_HML_UP_beta'].sum()\n",
    "    \n",
    "    monthly_Grundy = monthly_Grundy.append({'sum_ret': sum_ret, 'sum_residual_ret': sum_residual_ret,\n",
    "                                           'sum_port_alpha': sum_port_alpha, 'sum_port_mkt_beta': sum_port_mkt_beta,\n",
    "                                           'sum_port_SMB_beta': sum_port_SMB_beta, 'sum_port_HML_beta': sum_port_HML_beta,\n",
    "                                           'sum_port_mkt_UP_beta': sum_port_mkt_UP_beta,\n",
    "                                           'sum_port_SMB_UP_beta': sum_port_SMB_UP_beta,\n",
    "                                           'sum_port_HML_UP_beta': sum_port_HML_UP_beta,\n",
    "                                           'sum_residual_port_alpha': sum_residual_port_alpha,\n",
    "                                           'sum_residual_port_mkt_beta': sum_residual_port_mkt_beta,\n",
    "                                           'sum_residual_port_SMB_beta': sum_residual_port_SMB_beta,\n",
    "                                           'sum_residual_port_HML_beta': sum_residual_port_HML_beta,\n",
    "                                           'sum_residual_port_mkt_UP_beta': sum_residual_port_mkt_UP_beta,\n",
    "                                           'sum_residual_port_SMB_UP_beta': sum_residual_port_SMB_UP_beta,\n",
    "                                           'sum_residual_port_HML_UP_beta': sum_residual_port_HML_UP_beta},\n",
    "                                           ignore_index=True)\n",
    "                                            \n",
    "    return monthly_Grundy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf = pd.read_csv('msf.csv')\n",
    "msf_before = msf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "msf = data_cleaning(msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Zhikang Wang / Yulin Chen\n",
    "MAIN FUNCTION.\n",
    "Loop over the period from 1986 to generate rolling regression\n",
    "'''\n",
    "\n",
    "test_port = pd.DataFrame() #container for test df\n",
    "output_conditional_output = pd.DataFrame()    #container for Grundy Table output\n",
    "total_train_output = pd.DataFrame()\n",
    "\n",
    "dates = []\n",
    "ff = []\n",
    "start = 1926      #1926\n",
    "\n",
    "for i in range(890,1086): #（7，348） （348，659） （659，890）  (890，1086）\n",
    "    if (i%12) != 0:\n",
    "        month = i%12\n",
    "        year = i // 12 + start\n",
    "    if (i%12) == 0: \n",
    "        month = 12\n",
    "        year = i // 12 + start -1\n",
    "\n",
    "    ff_ret = format_FF()\n",
    "    train,test = rolling_time_window(month, year, 37, 1, 0, msf)\n",
    "    #train = get_equal_weight(train)\n",
    "    train = get_weight(train)\n",
    "    \n",
    "    train = train.rename(columns = {\"RET\": \"ticker_ret\", \"date\": \"YearMonth\"})\n",
    "    train = train[['YearMonth','PERMNO','ticker_ret','weight']]\n",
    "    train[\"PERMNO\"] = train[\"PERMNO\"].astype(str)\n",
    "    test[\"PERMNO\"] = test[\"PERMNO\"].astype(str)\n",
    "    train[\"YearMonth\"] = train[\"YearMonth\"].astype(str)\n",
    "    train['YearMonth'] = train['YearMonth'].apply(lambda x: x[:4] + x[5:7])\n",
    "    # Merging the two dataset into one combined return dataset, which will be used as regression input\n",
    "    combined_ret = pd.merge(ff_ret, train, how='right', on=['YearMonth'])\n",
    "    # calculates the excess return of tickers by subtracting the returns by risk free rate\n",
    "    combined_ret['ticker_excess_ret'] = combined_ret['ticker_ret'] - combined_ret['RF']\n",
    "    #append dates\n",
    "    month_list=[\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "    month=month_list[month-1]\n",
    "#     year = year + 3\n",
    "    str_date = str(year)+str(month)\n",
    "    dates.append(str_date)\n",
    "        \n",
    "    \n",
    "    sd_dic, output = all_regression(combined_ret)\n",
    "    \n",
    "    output_conditional_output = output_conditional_output.append(output)\n",
    "    total_train_output = total_train_output.append(output)\n",
    "#     monthly_Grundy = pd.DataFrame()\n",
    "    monthly_Grundy = pd.DataFrame(columns=['sum_ret','sum_residual_ret','sum_port_alpha','sum_port_mkt_beta',\n",
    "                                          'sum_port_SMB_beta','sum_port_HML_beta','sum_port_mkt_UP_beta',\n",
    "                                          'sum_port_SMB_UP_beta','sum_port_HML_UP_beta','sum_residual_port_alpha',\n",
    "                                          'sum_residual_port_mkt_beta','sum_residual_port_SMB_beta',\n",
    "                                          'sum_residual_port_HML_beta','sum_residual_port_mkt_UP_beta',\n",
    "                                          'sum_residual_port_SMB_UP_beta','sum_residual_port_HML_UP_beta'])\n",
    "    #monthly_Grundy = Grundy_Table(output_conditional, monthly_Grundy)\n",
    "    #output_conditional_output = pd.concat([output_conditional_output, monthly_Grundy])\n",
    "    \n",
    "#     sd_df = pd.DataFrame.from_dict(sd_dic, orient='index')\n",
    "#     sd_df = sd_df.reset_index()\n",
    "#     sd_df =  sd_df.rename(columns = {\"index\": \"PERMNO\", 0: 'std'})\n",
    "#     test = pd.merge(test,sd_df, how = 'left', on  =['PERMNO'])\n",
    "    \n",
    "    # Testing portfolio\n",
    "#     count = len(set(output['PERMNO'].values))\n",
    "#     output['test_conv_weight']=output['ticker_ret'].apply(lambda x: (x-output['ticker_ret'].mean())*(-1/count))\n",
    "#     output['test_red_weight'] = output['residual'].apply(lambda x: (x-output['residual'].mean())*(-1/count))\n",
    "#     output = output[['PERMNO','test_conv_weight','test_red_weight']]\n",
    "#     test = pd.merge(test,output,how = 'left',on=['PERMNO'])\n",
    "    test_port = test_port.append(test)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193302\n",
      "     mkt_ret     SMB     HML  mkt_ret_UP    SMB_UP    HML_UP\n",
      "158  -0.1524 -0.0275 -0.0273   -0.131085 -0.008257 -0.001140\n",
      "258  -0.1524 -0.0275 -0.0273   -0.119602  0.016611 -0.005281\n",
      "259  -0.1524 -0.0275 -0.0273   -0.137712  0.017645 -0.040525\n",
      "260  -0.1524 -0.0275 -0.0273   -0.144079 -0.020660 -0.026498\n",
      "261  -0.1524 -0.0275 -0.0273   -0.151924 -0.000405  0.003706\n",
      "262  -0.1524 -0.0275 -0.0273   -0.145805 -0.002697  0.000315\n",
      "263  -0.1524 -0.0275 -0.0273   -0.205748 -0.009533  0.007050\n",
      "264  -0.1524 -0.0275 -0.0273   -0.130329 -0.033141  0.004406\n",
      "265  -0.1524 -0.0275 -0.0273   -0.122686 -0.005763 -0.038174\n",
      "266  -0.1524 -0.0275 -0.0273   -0.105146 -0.028754  0.005389\n",
      "267  -0.1524 -0.0275 -0.0273   -0.172292  0.002569  0.013768\n",
      "268  -0.1524 -0.0275 -0.0273   -0.133349  0.007918  0.003649\n",
      "269  -0.1524 -0.0275 -0.0273   -0.092071  0.002300  0.005329\n",
      "270  -0.1524 -0.0275 -0.0273   -0.232475  0.013379  0.017768\n",
      "271  -0.1524 -0.0275 -0.0273   -0.113639 -0.003756  0.007589\n",
      "272  -0.1524 -0.0275 -0.0273   -0.108499  0.027546 -0.032834\n",
      "257  -0.1524 -0.0275 -0.0273   -0.176470 -0.000872  0.011900\n",
      "256  -0.1524 -0.0275 -0.0273   -0.085278 -0.018843  0.013420\n",
      "255  -0.1524 -0.0275 -0.0273   -0.178967  0.008794  0.002376\n",
      "254  -0.1524 -0.0275 -0.0273   -0.289621 -0.017231  0.008083\n",
      "238  -0.1524 -0.0275 -0.0273   -0.150081  0.038205 -0.040813\n",
      "239  -0.1524 -0.0275 -0.0273   -0.188872 -0.003800  0.005410\n",
      "240  -0.1524 -0.0275 -0.0273   -0.111223  0.010534 -0.002401\n",
      "241  -0.1524 -0.0275 -0.0273   -0.131180 -0.014804  0.002008\n",
      "242  -0.1524 -0.0275 -0.0273   -0.166804  0.005313  0.002556\n",
      "243  -0.1524 -0.0275 -0.0273   -0.248381 -0.006424 -0.001774\n",
      "244  -0.1524 -0.0275 -0.0273   -0.195154 -0.017039 -0.005077\n",
      "273  -0.1524 -0.0275 -0.0273   -0.229624 -0.020875  0.001248\n",
      "245  -0.1524 -0.0275 -0.0273   -0.160695 -0.005377  0.005235\n",
      "247  -0.1524 -0.0275 -0.0273   -0.081985  0.007108 -0.000873\n",
      "..       ...     ...     ...         ...       ...       ...\n",
      "224  -0.1524 -0.0275 -0.0273   -0.151521  0.015444 -0.015246\n",
      "216  -0.1524 -0.0275 -0.0273   -0.196929  0.011987  0.012086\n",
      "225  -0.1524 -0.0275 -0.0273   -0.093444  0.005882 -0.049431\n",
      "227  -0.1524 -0.0275 -0.0273   -0.066488 -0.022708  0.014162\n",
      "228  -0.1524 -0.0275 -0.0273   -0.034014  0.000615  0.002626\n",
      "229  -0.1524 -0.0275 -0.0273   -0.122912  0.004546 -0.025390\n",
      "230  -0.1524 -0.0275 -0.0273   -0.104871 -0.042575  0.002690\n",
      "231  -0.1524 -0.0275 -0.0273   -0.296543 -0.036823  0.008088\n",
      "232  -0.1524 -0.0275 -0.0273   -0.072339 -0.039049 -0.008857\n",
      "197  -0.1524 -0.0275 -0.0273   -0.155139 -0.001705 -0.030175\n",
      "226  -0.1524 -0.0275 -0.0273   -0.154070 -0.017429  0.009271\n",
      "215  -0.1524 -0.0275 -0.0273   -0.147004 -0.028261  0.008483\n",
      "223  -0.1524 -0.0275 -0.0273   -0.000544  0.002493  0.000564\n",
      "198  -0.1524 -0.0275 -0.0273   -0.142498  0.002791 -0.000416\n",
      "214  -0.1524 -0.0275 -0.0273   -0.202394  0.011010  0.001536\n",
      "199  -0.1524 -0.0275 -0.0273   -0.187833 -0.015679 -0.006563\n",
      "200  -0.1524 -0.0275 -0.0273   -0.307483 -0.005391  0.024056\n",
      "201  -0.1524 -0.0275 -0.0273   -0.133606  0.015907 -0.004597\n",
      "202  -0.1524 -0.0275 -0.0273   -0.148922  0.022549 -0.021920\n",
      "204  -0.1524 -0.0275 -0.0273   -0.152060  0.007280 -0.040637\n",
      "205  -0.1524 -0.0275 -0.0273   -0.205653  0.000603  0.005099\n",
      "206  -0.1524 -0.0275 -0.0273   -0.158745  0.003620  0.001363\n",
      "203  -0.1524 -0.0275 -0.0273   -0.160568  0.022936  0.007016\n",
      "208  -0.1524 -0.0275 -0.0273   -0.110153 -0.043691 -0.044019\n",
      "209  -0.1524 -0.0275 -0.0273   -0.168214  0.000268  0.012601\n",
      "210  -0.1524 -0.0275 -0.0273   -0.167231  0.002033  0.007979\n",
      "211  -0.1524 -0.0275 -0.0273   -0.136274  0.000209  0.016278\n",
      "212  -0.1524 -0.0275 -0.0273   -0.185634 -0.004217  0.017833\n",
      "213  -0.1524 -0.0275 -0.0273   -0.142099  0.006304 -0.015992\n",
      "207  -0.1524 -0.0275 -0.0273   -0.150089  0.007976 -0.000498\n",
      "\n",
      "[156 rows x 6 columns]\n",
      "mkt_ret      -0.022801\n",
      "SMB          -0.004114\n",
      "HML          -0.004084\n",
      "mkt_ret_UP    1.083821\n",
      "SMB_UP        0.435300\n",
      "HML_UP        1.753291\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robin\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4375\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4376\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 6",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-d2e2c43d883b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_conditional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_conditional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'YearMonth'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m#going through each ticker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mcombined_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconditional_factor_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#running Grundy regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0moutput_conditional\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_conditional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#output_conditional = get_weight_Residual(output_conditional)    #adding residual weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-d073ca7d17b7>\u001b[0m in \u001b[0;36mconditional_factor_model\u001b[1;34m(temp_conditional)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# temp_conditional has many rows of single PERMNO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     temp_conditional['residual'] = (y - x['mkt_ret']*coef[1] - x['SMB']*coef[2] - x['HML']*coef[3] -\n\u001b[1;32m---> 34\u001b[1;33m                                     x['mkt_ret_UP']*coef[4] - x['SMB_UP']*coef[5] - x['HML_UP']*coef[6] - coef[0])\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mstandard_dev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_conditional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'residual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get the sd of the residual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mavg_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_conditional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'residual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4380\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4381\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4382\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4383\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    @author: Robin Lam\n",
    "    Evaluating the reversal returns using a conditional factor model (Grundy and Martin)\n",
    "    \n",
    "        if excess returns on the RMRF, SMB, HML factors in month t are positive, use that factor;\n",
    "        otherwise, factor = 0.\n",
    "'''\n",
    "# df_conditional = output_conditional_output\n",
    "# df_conditional = df_conditional[['YearMonth','PERMNO','mkt_ret','SMB','HML','RF',\n",
    "#                                     'ticker_ret','ticker_excess_ret','weight',\n",
    "#                                     'mkt_factor','SMB_factor','HML_factor']]\n",
    "\n",
    "# # calculating the sum of all returns on factors and shifting all returns on factors down 1 (t-1)\n",
    "# df_sum_factors = df_conditional.groupby(['YearMonth'])[['mkt_factor','SMB_factor','HML_factor']].apply(lambda x: x.sum())\n",
    "# df_sum_factors = df_sum_factors.rename(columns={'mkt_factor':'mkt_factor_prev', 'SMB_factor':'SMB_factor_prev', 'HML_factor':'HML_factor_prev'})\n",
    "# df_sum_factors = df_sum_factors.shift(1)\n",
    "# df_combined = pd.merge(df_conditional, df_sum_factors, how='left', on=['YearMonth'])\n",
    "# df_combined = df_combined.dropna()\n",
    "# df_combined = df_combined.sort_values(by=['YearMonth'])\n",
    "\n",
    "\n",
    "# df_combined.loc[df_combined['mkt_factor_prev'] > 0, 'mkt_ret_UP'] = df_combined['mkt_ret']    # this month, t\n",
    "# df_combined.loc[df_combined['mkt_factor_prev'] <= 0, 'mkt_ret_UP'] = 0 \n",
    "# df_combined.loc[df_combined['SMB_factor_prev'] > 0, 'SMB_UP'] = df_combined['SMB']    # this month, t\n",
    "# df_combined.loc[df_combined['SMB_factor_prev'] <= 0, 'SMB_UP'] = 0\n",
    "# df_combined.loc[df_combined['HML_factor_prev'] > 0, 'HML_UP'] = df_combined['HML']    # this month, t\n",
    "# df_combined.loc[df_combined['HML_factor_prev'] <= 0, 'HML_UP'] = 0\n",
    "# df_combined = df_combined.drop(columns=['mkt_factor','SMB_factor','HML_factor'])\n",
    "\n",
    "# print(df_combined[df_combined['YearMonth']=='193303'])\n",
    "\n",
    "df_conditional = format_Grundy(output_conditional_output)\n",
    "\n",
    "output_conditional = pd.DataFrame()\n",
    "YearMonth_list = list(set(df_conditional['YearMonth'].values.tolist()))\n",
    "for i in YearMonth_list:\n",
    "    print(i)\n",
    "    temp = df_conditional[df_conditional['YearMonth'] == i]    #going through each ticker\n",
    "    combined_ret = conditional_factor_model(temp)    #running Grundy regression\n",
    "    output_conditional = output_conditional.append(combined_ret)\n",
    "#output_conditional = get_weight_Residual(output_conditional)    #adding residual weight\n",
    "output_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv1 = total_train_output.to_csv ('train_output4.csv', index = None, header=True)\n",
    "export_csv2 = test_port.to_csv ('test_output4.csv', index = None, header=True)\n",
    "export_csv3 = output_conditional_output.to_csv ('conditional_output4.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
